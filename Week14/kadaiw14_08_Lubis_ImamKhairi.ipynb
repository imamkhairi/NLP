{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 課題1：\n",
        "\n",
        "以下に示すコードでは、cols[0]は正解極性、cols[1]は予測極性、dols[2]はコメントの要素になります。24行目から cols[0], cols[1]を参照しそれぞれのpositiveとnegativeをカウントしています。<br>\n",
        "課題1では、week10で学んだ、TP, FP, FN, TNを求めます。<br>\n",
        "\n",
        "4行目からの`def 関数名(引数)`は評価値を算出する処理を関数として定義しています。関数を使う場合は、`関数名(引数)`として使えます。（他の言語と同様ですね）<br>\n",
        "36〜39行目に各評価指標の式を追加し、結果表示させ、分類精度を確認しましょう。"
      ],
      "metadata": {
        "id": "nKVC53EpZKUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fname_result = 'result.txt' #sentence polarity dataset v1.0極性分類結果のファイル\n",
        "\n",
        "#評価値を算出する関数 score(fname)を定義する\n",
        "def score(fname):\n",
        "    '''結果ファイルからスコア算出\n",
        "    結果ファイルを読み込んで、正解率、適合率、再現率、F1スコアを返す\n",
        "    戻り値：\n",
        "    正解率,適合率,再現率,F1スコア\n",
        "    '''\n",
        "    # 結果を読み込んで集計する。各変数の初期値を代入する。\n",
        "    TP = 0      # True-Positive     予想が+1、正解も+1\n",
        "    FP = 0      # False-Positive    予想が+1、正解は-1\n",
        "    FN = 0      # False-Negative    予想が-1、正解は+1\n",
        "    TN = 0      # True-Negative     予想が-1、正解も-1\n",
        "\n",
        "    with open(fname) as data_file: #ファイルをopenし，data_fileとする\n",
        "        for line in data_file:\n",
        "            cols = line.split('\\t')    # \"-1  -1  0.7992886809287588\"の並びのデータをtabで分割しリスト化\n",
        "#            print(cols)   #colsの内容を表示\n",
        "\n",
        "            if len(cols) < 3:\n",
        "                continue\n",
        "\n",
        "            if cols[0] == '+1':         # 0番目：正解極性\n",
        "                if cols[1] == '+1':     # 1番目：予想極性\n",
        "                    TP += 1\n",
        "                else:\n",
        "                    FN += 1\n",
        "            else:\n",
        "                if cols[1] == '+1':\n",
        "                    FP += 1\n",
        "                else:\n",
        "                    TN += 1\n",
        "\n",
        "    # 各指標の算出式:ここに各指標の式をTP, FN, FP, TNを用い入力します。演算子は一般的な書式　＋、ー、＊、＼　優先する計算は（）を使えます。\n",
        "    accuracy = (TP + TN) / (TP + FN + FP + TN)    # 正解率\n",
        "    precision = TP / (TP+FP)     # 適合率\n",
        "    recall = TP/(TP+FN)    # 再現率\n",
        "    f1 = (2*precision*recall) / (recall + precision)   # F1スコア\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "#def score(fname)の終わり\n",
        "\n",
        "# スコア算出 定義したscoreにデータを渡し，　return の返す値を左から順に各変数に格納する。\n",
        "accuracy, precision, recall, f1 = score(fname_result)\n",
        "print('正解率　\\t{}\\n適合率　\\t{}\\n再現率　\\t{}\\nF1スコア　\\t{}'.format( accuracy, precision, recall, f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAUH9v87aHYt",
        "outputId": "8a4a8cdb-c41e-42d2-93e1-9555cf163cd1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正解率　\t0.7477485928705441\n",
            "適合率　\t0.7476092255765986\n",
            "再現率　\t0.748030018761726\n",
            "F1スコア　\t0.7478195629747725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題2：\n",
        "\n",
        "まず初めに、データになる頻度ベクトルを生成します。以下の手順でコード、コメントおよび式を確認しながら課題を進めていきましょう。`print`文の前の`#`コメント記号は適宜、削除/追加しながら進めてください。<br>\n",
        "\n",
        "1. 23行目　corpusの頻度ベクトルの確認\n",
        "\n",
        "### ※コードの行番号は、[ESC]+l もしくは操作タブの「表示」->行番号をトグル で表示/非表示ができます。"
      ],
      "metadata": {
        "id": "iPKy9TZLirRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import normalize #データの正規化などが可能な\n",
        "import numpy as np #数値計算用ライブラリpnumpyをnpと名前をつけて以下で利用\n",
        "import pandas as pd #データ解析用ライブラリpandasをpdと名前をつけて以下で利用\n",
        "\n",
        "#以下の4文のリストを文書コーパスとして使う．\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?'\n",
        "]\n",
        "\n",
        "smooth_idf = True\n",
        "norm_idf = True\n",
        "\n",
        "# 文章ごとの頻度ベクトルを作る\n",
        "wc = CountVectorizer()\n",
        "x = wc.fit_transform(corpus)\n",
        "wcX = np.array(x.toarray())\n",
        "\n",
        "print('4文コーパス: \\n', corpus, '\\n') #corpusを表示\n",
        "print('頻度ベクトル: \\n', wcX,'\\n')  #orpusの頻度ベクトルの確認"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6JYibZaisTj",
        "outputId": "5b3fa1a8-7317-4f7d-c2c7-629dc8509949"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4文コーパス: \n",
            " ['This is the first document.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document?'] \n",
            "\n",
            "頻度ベクトル: \n",
            " [[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題3：\n"
      ],
      "metadata": {
        "id": "LZ9GrvSki1xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ここまで実行したコードは有効なので，続きとして実行していきます．\n",
        "\n",
        "# term frequency(TF) 単語の頻出度を求める:\n",
        "N = wcX.shape[0]\n",
        "\n",
        "tf = np.array([wcX[i, :] / np.sum(wcX, axis=1)[i] for i in range(N)])\n",
        "\n",
        "print('4文コーパス: \\n', corpus, '\\n') #corpusを表示\n",
        "print('全文書数： ', N, '\\n') #全文書数の確認\n",
        "\n",
        "\n",
        "print('wcX[i, :] \\n', [wcX[i, :]for i in range(N)], '\\n') #wcX[i, :]の確認\n",
        "print('words_freq \\n', [np.sum(wcX, axis=1)[i]for i in range(N)], '\\n')#各文の単語の出現頻度(単語数)の確認\n",
        "print('tf \\n', tf, '\\n')\n",
        "\n",
        "# inverse documents frequency(IDF) 逆文書頻度を求める,  df:単語Xを含む文書数 :\n",
        "df = np.count_nonzero(wcX, axis=0) \n",
        "print('df: ', df, '\\n') #df の確認\n",
        "\n",
        "idf = np.log((1 + N) / (1 + df) )+ 1  if smooth_idf else np.log( N / df )  #全文書数と単語Xを含む文書数に1を足しているのは，滑らかな値にするため\n",
        "print('idf :', idf, '\\n')\n",
        "\n",
        "#TF-IDFを求め、正規化(normalize)する．\n",
        "tfidf = normalize(tf*idf) if norm_idf else tf*idf\n",
        "\n",
        "#tfidfを格納するデータフレーム(columns:列ラベル，index:行ラベル)形式にする. df_tifidf の dfはデータフレームの意味で付けました．\n",
        "df_tfidf = pd.DataFrame(tfidf, columns=wc.get_feature_names())\n",
        "\n",
        "print(df_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-pzzj8JjAED",
        "outputId": "2a5b9dbb-094c-43f9-b596-44402a62ad49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4文コーパス: \n",
            " ['This is the first document.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document?'] \n",
            "\n",
            "全文書数：  4 \n",
            "\n",
            "wcX[i, :] \n",
            " [array([0, 1, 1, 1, 0, 0, 1, 0, 1]), array([0, 2, 0, 1, 0, 1, 1, 0, 1]), array([1, 0, 0, 1, 1, 0, 1, 1, 1]), array([0, 1, 1, 1, 0, 0, 1, 0, 1])] \n",
            "\n",
            "words_freq \n",
            " [5, 6, 6, 5] \n",
            "\n",
            "tf \n",
            " [[0.         0.2        0.2        0.2        0.         0.\n",
            "  0.2        0.         0.2       ]\n",
            " [0.         0.33333333 0.         0.16666667 0.         0.16666667\n",
            "  0.16666667 0.         0.16666667]\n",
            " [0.16666667 0.         0.         0.16666667 0.16666667 0.\n",
            "  0.16666667 0.16666667 0.16666667]\n",
            " [0.         0.2        0.2        0.2        0.         0.\n",
            "  0.2        0.         0.2       ]] \n",
            "\n",
            "df:  [1 3 2 4 1 1 4 1 4] \n",
            "\n",
            "idf : [1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
            " 1.         1.91629073 1.        ] \n",
            "\n",
            "        and  document     first        is       one    second       the  \\\n",
            "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
            "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
            "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
            "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
            "\n",
            "      third      this  \n",
            "0  0.000000  0.384085  \n",
            "1  0.000000  0.281089  \n",
            "2  0.511849  0.267104  \n",
            "3  0.000000  0.384085  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(df_tfidf['and']) # access based on column \n",
        "# print(df_tfidf.iloc[1]) # access based on row index\n",
        "\n",
        "def getCharacteristicWord():\n",
        "  result = [[] for i in range(len(df_tfidf[\"and\"]))]\n",
        "  # result[1].append(\"kkk\")\n",
        "\n",
        "  for column in df_tfidf.columns:\n",
        "    for i in range(len(df_tfidf[column])):\n",
        "      if (df_tfidf[column].iloc[i] > 0.45):\n",
        "        result[i].append(column)\n",
        "        # print(i, column)\n",
        "\n",
        "  for i in range(len(result)):\n",
        "    print(\"文書\",i,result[i])"
      ],
      "metadata": {
        "id": "CKJ2Kp_Sj4t8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getCharacteristicWord()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLu519g9j7y5",
        "outputId": "f752c627-6366-42c5-8f14-665568d72c28"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "文書 0 ['first']\n",
            "文書 1 ['document', 'second']\n",
            "文書 2 ['and', 'one', 'third']\n",
            "文書 3 ['first']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "文書ごとに各単語の特徴的である重要度が計算できました。<br>\n",
        "出力結果を確認し、文書0~3の特徴のある単語($tf \\cdot idf > 0.45$とした場合)を答えてください。複数ある場合は、カンマで区切ること。<br>\n",
        "- 文書0: document, first\n",
        "- 文書1: document, second\n",
        "- 文書2: and, one, third\n",
        "- 文書3: document, first\n",
        "\n",
        "考察： 閾値を0.45としましたが，各文書の特徴的な単語になっているようでしょうか。   \n",
        "出力結果を見て，適切な閾値を決める，または，上位何位までを特徴のある単語とするなどの方法で特徴ある単語として自動的に決めることが可能になります。\n",
        "\n",
        "考察： 文章の特徴的な単語となる単語の最小値として 0.45 を使用すると、実際には文章の特徴を示さない単語がいくつか得られます。 <br>\n",
        "条件として値を変更することで、結果はより正確になります。"
      ],
      "metadata": {
        "id": "zJSGBA32j8zF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題4：\n",
        "\n",
        "1. corpusは方法1と同じリストを利用します。ライブラリを読み込んだ後に追加してください。\n",
        "2. corpusを追加する前の，6行目の `x`　に次の式を設定します。<br>\n",
        "- TfidfVectorizer()でtf-idfを求める関数は `fit_transform()` が用意されています。\n",
        "- 5行目で fidfVectorizer()のインスタンスを `tfidf`に設定します。\n",
        "- 使い方は、`tfidf`の後に ドット`.`　で`fit_transform()`を指定するだけです。() には文書(ここではcorpus)を指定します。\n",
        "3. 実行し、結果が方法1とほぼ同様になるか確認しましょう。"
      ],
      "metadata": {
        "id": "9v5_cKFukAUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "#TfidfVectorizerに用意されている .fit_transform を用いtf-idfを算出する。\n",
        "tfidf = TfidfVectorizer()\n",
        "x = tfidf.fit_transform(corpus);\n",
        "\n",
        "#tfidfの結果をみるために、データフレームに変換します．pandasのimportが必要\n",
        "df_tfidf = pd.DataFrame(x.toarray(), columns=tfidf.get_feature_names())\n",
        "\n",
        "print('TF・IDF:')\n",
        "print(df_tfidf)\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykfgj0Olkn4o",
        "outputId": "6a87f0a7-c75d-4619-a0a3-8b18253199fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF・IDF:\n",
            "        and  document     first        is       one    second       the  \\\n",
            "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
            "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
            "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
            "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
            "\n",
            "      third      this  \n",
            "0  0.000000  0.384085  \n",
            "1  0.000000  0.281089  \n",
            "2  0.511849  0.267104  \n",
            "3  0.000000  0.384085  \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TfidfVectorizer()を用いることで，単語のtf-idfを簡単に求めることができました。<br>\n",
        "考察： 方法1と方法2の結果を比較するとどうですか？\n",
        "\n",
        "考察：方法１と同じ結果が出ました。"
      ],
      "metadata": {
        "id": "XD8ZCkC3nfmA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bldBDkx4pfyJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}