{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#PRFA"
      ],
      "metadata": {
        "id": "I2HSQNqC_DE3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3F9RIrX94gk",
        "outputId": "6c293a93-d040-41ba-d560-a55d2e786c85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1\t+1\t0.8090167766614191\n",
            "+1\t-1\t0.7003345711279827\n",
            "+1\t+1\t0.8934079362719148\n",
            "+1\t-1\t0.5888134147222777\n",
            "-1\t+1\t0.6841139569492246\n",
            "-1\t-1\t0.8916877017979264\n",
            "+1\t+1\t0.6436652826341255\n",
            "-1\t+1\t0.6283518605091021\n",
            "+1\t+1\t0.9917435322789024\n",
            "+1\t+1\t0.9254167173395523\n"
          ]
        }
      ],
      "source": [
        "!head result.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fname_result = 'result.txt' #sentence polarity dataset v1.0極性分類結果のファイル\n",
        "\n",
        "#評価値を算出する関数 score(fname)を定義する\n",
        "def score(fname):\n",
        "    '''結果ファイルからスコア算出\n",
        "    結果ファイルを読み込んで、正解率、適合率、再現率、F1スコアを返す\n",
        "    戻り値：\n",
        "    正解率,適合率,再現率,F1スコア\n",
        "    '''\n",
        "    # 結果を読み込んで集計する。各変数の初期値を代入する。\n",
        "    TP = 0      # True-Positive     予想が+1、正解も+1\n",
        "    FP = 0      # False-Positive    予想が+1、正解は-1\n",
        "    FN = 0      # False-Negative    予想が-1、正解は+1\n",
        "    TN = 0      # True-Negative     予想が-1、正解も-1\n",
        "\n",
        "    with open(fname) as data_file: #ファイルをopenし，data_fileとする\n",
        "        for line in data_file:\n",
        "            cols = line.split('\\t')    # \"-1  -1  0.7992886809287588\"の並びのデータをtabで分割しリスト化\n",
        "#            print(cols)   #colsの内容を表示\n",
        "\n",
        "            if len(cols) < 3:\n",
        "                continue\n",
        "\n",
        "            if cols[0] == '+1':         # 0番目：正解極性\n",
        "                if cols[1] == '+1':     # 1番目：予想極性\n",
        "                    TP += 1\n",
        "                else:\n",
        "                    FN += 1\n",
        "            else:\n",
        "                if cols[1] == '+1':\n",
        "                    FP += 1\n",
        "                else:\n",
        "                    TN += 1\n",
        "\n",
        "    # 各指標の算出式:ここに各指標の式をTP, FN, FP, TNを用い入力します。演算子は一般的な書式　＋、ー、＊、＼　優先する計算は（）を使えます。\n",
        "    accuracy = (TP + TN) / (TP + FN + FP + TN)    # 正解率\n",
        "    precision = TP / (TP+FP)     # 適合率\n",
        "    recall = TP/(TP+FN)    # 再現率\n",
        "    f1 = (2*precision*recall) / (recall + precision)   # F1スコア\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "#def score(fname)の終わり\n",
        "\n",
        "# スコア算出 定義したscoreにデータを渡し，　return の返す値を左から順に各変数に格納する。\n",
        "accuracy, precision, recall, f1 = score(fname_result)\n",
        "print('正解率　\\t{}\\n適合率　\\t{}\\n再現率　\\t{}\\nF1スコア　\\t{}'.format( accuracy, precision, recall, f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxcmXCLF-cXV",
        "outputId": "5e2cf78a-7c3d-4705-9055-08a911c6635b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正解率　\t0.7477485928705441\n",
            "適合率　\t0.7476092255765986\n",
            "再現率　\t0.748030018761726\n",
            "F1スコア　\t0.7478195629747725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "liat lagi yang ditanyakan di soal 考察"
      ],
      "metadata": {
        "id": "SyHwMcF-_26a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tf-idf"
      ],
      "metadata": {
        "id": "jWepDBd3Aah_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep sklearn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63xceKc0BSaO",
        "outputId": "5923e3e6-d3a4-428b-e200-4ce3bf84f0fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sklearn-pandas                1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import normalize #データの正規化などが可能な\n",
        "import numpy as np #数値計算用ライブラリpnumpyをnpと名前をつけて以下で利用\n",
        "import pandas as pd #データ解析用ライブラリpandasをpdと名前をつけて以下で利用\n",
        "\n",
        "#以下の4文のリストを文書コーパスとして使う．\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?'\n",
        "]\n",
        "\n",
        "smooth_idf = True\n",
        "norm_idf = True\n",
        "\n",
        "# 文章ごとの頻度ベクトルを作る\n",
        "wc = CountVectorizer()\n",
        "\n",
        "# print(wc.get_feature_names_out())\n",
        "# ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
        "#    0        1         2     3     4    5        6      7       8\n",
        "\n",
        "x = wc.fit_transform(corpus)\n",
        "\n",
        "print(x)\n",
        "\n",
        "wcX = np.array(x.toarray())\n",
        "\n",
        "print('4文コーパス: \\n', corpus, '\\n') #corpusを表示\n",
        "print('頻度ベクトル: \\n', wcX,'\\n')  #orpusの頻度ベクトルの確認"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS9u4xCxBgrU",
        "outputId": "1302e5ca-cccf-4b92-9488-aee3e9f9e67f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 8)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 1)\t1\n",
            "  (1, 8)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 1)\t2\n",
            "  (1, 5)\t1\n",
            "  (2, 8)\t1\n",
            "  (2, 3)\t1\n",
            "  (2, 6)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 4)\t1\n",
            "  (3, 8)\t1\n",
            "  (3, 3)\t1\n",
            "  (3, 6)\t1\n",
            "  (3, 2)\t1\n",
            "  (3, 1)\t1\n",
            "4文コーパス: \n",
            " ['This is the first document.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document?'] \n",
            "\n",
            "頻度ベクトル: \n",
            " [[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ここまで実行したコードは有効なので，続きとして実行していきます．\n",
        "\n",
        "# term frequency(TF) 単語の頻出度を求める:\n",
        "N = wcX.shape[0]\n",
        "\n",
        "# print(wcX.shape)\n",
        "# (4, 9)\n",
        "\n",
        "\n",
        "tf = np.array([wcX[i, :] / np.sum(wcX, axis=1)[i] for i in range(N)])\n",
        "#di bawah ada ditulis masing2\n",
        "\n",
        "print('4文コーパス: \\n', corpus, '\\n') #corpusを表示\n",
        "print('全文書数： ', N, '\\n') #全文書数の確認\n",
        "\n",
        "\n",
        "print('wcX[i, :] \\n', [wcX[i, :]for i in range(N)], '\\n') #wcX[i, :]の確認\n",
        "\n",
        "print('words_freq \\n', [np.sum(wcX, axis=1)[i]for i in range(N)], '\\n')#各文の単語の出現頻度(単語数)の確認\n",
        "# axis=1 disini akan membuat numpy sum seluruh data per document(baris) (liat di atas arraynya)\n",
        "\n",
        "print('tf \\n', tf, '\\n')\n",
        "\n",
        "# inverse documents frequency(IDF) 逆文書頻度を求める,  df:単語Xを含む文書数 :\n",
        "df = np.count_nonzero(wcX, axis=0) # berapa banyak document yang memuat kata tertentu, axis 0 = vertical\n",
        "print('df: ', df, '\\n') #df の確認\n",
        "\n",
        "idf = np.log((1 + N) / (1 + df) )+ 1  if smooth_idf else np.log( N / df )  #全文書数と単語Xを含む文書数に1を足しているのは，滑らかな値にするため\n",
        "print('idf :', idf, '\\n')\n",
        "\n",
        "#TF-IDFを求め、正規化(normalize)する．\n",
        "tfidf = normalize(tf*idf) if norm_idf else tf*idf\n",
        "\n",
        "#tfidfを格納するデータフレーム(columns:列ラベル，index:行ラベル)形式にする. df_tifidf の dfはデータフレームの意味で付けました．\n",
        "df_tfidf = pd.DataFrame(tfidf, columns=wc.get_feature_names())\n",
        "\n",
        "print(df_tfidf)\n",
        "# bikin yang buat nyari >0.45"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLTF3RSmBk2z",
        "outputId": "cc39f369-3f71-4cce-aeec-7b8303d61388"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4文コーパス: \n",
            " ['This is the first document.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document?'] \n",
            "\n",
            "全文書数：  4 \n",
            "\n",
            "wcX[i, :] \n",
            " [array([0, 1, 1, 1, 0, 0, 1, 0, 1]), array([0, 2, 0, 1, 0, 1, 1, 0, 1]), array([1, 0, 0, 1, 1, 0, 1, 1, 1]), array([0, 1, 1, 1, 0, 0, 1, 0, 1])] \n",
            "\n",
            "words_freq \n",
            " [5, 6, 6, 5] \n",
            "\n",
            "tf \n",
            " [[0.         0.2        0.2        0.2        0.         0.\n",
            "  0.2        0.         0.2       ]\n",
            " [0.         0.33333333 0.         0.16666667 0.         0.16666667\n",
            "  0.16666667 0.         0.16666667]\n",
            " [0.16666667 0.         0.         0.16666667 0.16666667 0.\n",
            "  0.16666667 0.16666667 0.16666667]\n",
            " [0.         0.2        0.2        0.2        0.         0.\n",
            "  0.2        0.         0.2       ]] \n",
            "\n",
            "df:  [1 3 2 4 1 1 4 1 4] \n",
            "\n",
            "idf : [1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
            " 1.         1.91629073 1.        ] \n",
            "\n",
            "        and  document     first        is       one    second       the  \\\n",
            "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
            "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
            "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
            "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
            "\n",
            "      third      this  \n",
            "0  0.000000  0.384085  \n",
            "1  0.000000  0.281089  \n",
            "2  0.511849  0.267104  \n",
            "3  0.000000  0.384085  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(df_tfidf['and']) # access based on column \n",
        "# print(df_tfidf.iloc[1]) # access based on row index\n",
        "\n",
        "def getCharacteristicWord():\n",
        "  result = [[] for i in range(len(df_tfidf[\"and\"]))]\n",
        "  # result[1].append(\"kkk\")\n",
        "\n",
        "  for column in df_tfidf.columns:\n",
        "    for i in range(len(df_tfidf[column])):\n",
        "      if (df_tfidf[column].iloc[i] > 0.45):\n",
        "        result[i].append(column)\n",
        "        # print(i, column)\n",
        "\n",
        "  for i in range(len(result)):\n",
        "    print(\"文書\",i,result[i])"
      ],
      "metadata": {
        "id": "qXWcRG-_C5vH"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getCharacteristicWord()"
      ],
      "metadata": {
        "id": "-jrQ1mVoXD0X",
        "outputId": "9d081f48-e174-4982-c4af-8130d3715b6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "文書 0 ['document', 'first']\n",
            "文書 1 ['document', 'second']\n",
            "文書 2 ['and', 'one', 'third']\n",
            "文書 3 ['document', 'first']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt-3SkQ3IoIa"
      },
      "source": [
        "## 課題3：\n",
        "文書ごとに各単語の特徴的である重要度が計算できました。<br>\n",
        "出力結果を確認し、文書0~3の特徴のある単語($tf \\cdot idf > 0.45$とした場合)を答えてください。複数ある場合は、カンマで区切ること。<br>\n",
        "- 文書0: document, first\n",
        "- 文書1: document, second \n",
        "- 文書2: and, one, third\n",
        "- 文書3: document, first\n",
        "\n",
        "考察： 閾値を0.45としましたが，各文書の特徴的な単語になっているようでしょうか。   \n",
        "出力結果を見て，適切な閾値を決める，または，上位何位までを特徴のある単語とするなどの方法で特徴ある単語として自動的に決めることが可能になります。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "#TfidfVectorizerに用意されている .fit_transform を用いtf-idfを算出する。\n",
        "tfidf = TfidfVectorizer()\n",
        "x = tfidf.fit_transform(corpus);\n",
        "\n",
        "#tfidfの結果をみるために、データフレームに変換します．pandasのimportが必要\n",
        "df_tfidf = pd.DataFrame(x.toarray(), columns=tfidf.get_feature_names())\n",
        "\n",
        "print('TF・IDF:')\n",
        "print(df_tfidf)\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQkgUxQCG8GI",
        "outputId": "b63b34da-2c24-40bb-ce8a-2b6ebded2f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF・IDF:\n",
            "        and  document     first        is       one    second       the  \\\n",
            "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
            "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
            "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
            "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
            "\n",
            "      third      this  \n",
            "0  0.000000  0.384085  \n",
            "1  0.000000  0.281089  \n",
            "2  0.511849  0.267104  \n",
            "3  0.000000  0.384085  \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 課題4：\n",
        "\n",
        "1. corpusは方法1と同じリストを利用します。ライブラリを読み込んだ後に追加してください。\n",
        "2. corpusを追加する前の，6行目の `x`　に次の式を設定します。<br>\n",
        "- TfidfVectorizer()でtf-idfを求める関数は `fit_transform()` が用意されています。\n",
        "- 5行目で fidfVectorizer()のインスタンスを `tfidf`に設定します。\n",
        "- 使い方は、`tfidf`の後に ドット`.`　で`fit_transform()`を指定するだけです。() には文書(ここではcorpus)を指定します。\n",
        "3. 実行し、結果が方法1とほぼ同様になるか確認しましょう。"
      ],
      "metadata": {
        "id": "x3rozVkCJRZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TfidfVectorizer()を用いることで，単語のtf-idfを簡単に求めることができました。<br>\n",
        "\n",
        "考察： 方法1と方法2の結果を比較するとどうですか？\n",
        "\n",
        "このようにpythonでは便利な関数が用意されているので、使った方が便利ですね。pythonで用意されている関数は以前紹介した PyPIに集約されています。https://pypi.org/"
      ],
      "metadata": {
        "id": "nG3HZyTmJUYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "getCharacteristicWord()"
      ],
      "metadata": {
        "id": "BfNPZaHfJXme",
        "outputId": "78e9965d-7719-408c-8aa0-21f551d5f398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "文書 0 ['document', 'first']\n",
            "文書 1 ['document', 'second']\n",
            "文書 2 ['and', 'one', 'third']\n",
            "文書 3 ['document', 'first']\n"
          ]
        }
      ]
    }
  ]
}