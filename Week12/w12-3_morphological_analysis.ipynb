{"cells":[{"cell_type":"markdown","metadata":{"id":"GVLRJNsrxcIZ"},"source":["# 形態素解析\n","形態素解析とは、自然言語を形態素にまで分割することです。  \n","形態素とは、言葉が意味を持つまとまりの単語の最小単位のことです。  \n","今回は、形態素解析を用いて単語に分割します。  "]},{"cell_type":"markdown","metadata":{"id":"HQlQVVz9xcIc"},"source":["## Janome\n","\n","形態素解析器 Janomeを使って形態素解析を行いましょう。  \n","Tokenizerをインポートします。  \n","\n","pythonのパッケージやモジュールは以下のコマンドでインストール可能です。  例えばjanomeをインストールしたい時は、<br>\n","\n","- `pip install janome`（端末からインストールする場合）\n","- `!pip install janome`（jupyter notebookでln[]の行からインストールする場合）\n","\n","標準ライブラリ以外で必要なパッケージやモジュールをインストールする場合は、所望のパッケージやモジュールをjanomeのところを書き換えるとインストールでき、python　からインポートできるようになります。\n","pythonで使えるライブライ等は、こちらを参照するか、webで検索してみてください。<br>\n","- PyPI(Python Package Index) https://pypi.org/\n","Search の窓で　'janome'や're'などで検索すると，パッケージの名前、使い方などがわかります。英語ですが、現在のところ他言語利用者はこのページを頼りにしています。<br>\n","- パッケージのバージョンが上がると、これまで動作していたコードが動作しない場合もあります。その時は，バージョンを指定してインストールする，また，変更点を調べコードを変更するなどが必要になります。ちなみに，今回実習で利用しているjanomeのバージョンは3.8を使っています。\n","\n","### 今回の実習では利用するパッケージ等は予めインストールしていますので、インストールは不要です。\n"]},{"cell_type":"markdown","metadata":{"id":"F2bsloTcxcId"},"source":["## 1. janomeの動作確認"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zfA7P4xbxcId"},"outputs":[],"source":["from janome.tokenizer import Tokenizer\n","\n","t = Tokenizer()\n","\n","s = \"すもももももももものうち\"\n","\n","for token in t.tokenize(s):\n","    print(token)"]},{"cell_type":"markdown","metadata":{"id":"qq8JXuaJxcIe"},"source":["形態素解析器は辞書を参照し、解析します。<br>\n","辞書には，　 ipadicやipadic-neologd(現代に合わせた辞書)があります。<br>\n","端末から使ったmecabの結果と比較してどうでしょうか。<br>\n","mecabもmecab-ipadic, mecab-ipadic-neologdの辞書を利用します。<br>\n","辞書が同じであれば同じ結果を得られます。<br>\n","今回はどちらを使っているのかは，`アラレちゃんは怪力少女です。`を実行してみてください。<br>\n","- アラレ\n","- ちゃん\n","\n","または，\n","- アラレちゃん\n","\n","前者の場合はipadic, 後者はipadic-neologd。辞書は辞書のダウンロードと設定で変更可能です。<br>"]},{"cell_type":"markdown","metadata":{"id":"I5Qql69MxcIe"},"source":["## 2. 分かち書き\n","Janomeを使って分かち書きを行います。  \n","分かち書きとは、文章を単語ごとに分割することです。  \n","`tokenize`の際に引数を`wakati=True`にすることで、各単語をリストに格納できます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9TVHzWI_xcIf"},"outputs":[],"source":["from janome.tokenizer import Tokenizer\n","\n","t = Tokenizer()\n","\n","s = \"すもももももももものうち\"\n","\n","word_list = t.tokenize(s, wakati=True)\n","print(word_list)"]},{"cell_type":"markdown","metadata":{"id":"S8RmeJDQxcIf"},"source":["## 3. コーパスを分かち書き\n","前回前処理を行った「我輩は猫である」に対して、分かち書きを行います。  (注意：wagahai_list.pickleが同じディレクトリにあること)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CAPjAiwoxcIf"},"outputs":[],"source":["from janome.tokenizer import Tokenizer\n","import pickle\n","\n","t = Tokenizer()\n","\n","with open('wagahai_list.pickle', mode='rb') as f:#pickleにしたファイルを読み込んでリストにする．\n","    wagahai_list = pickle.load(f)\n","\n","for sentence in wagahai_list:\n","    print(t.tokenize(sentence, wakati=True))"]},{"cell_type":"markdown","metadata":{"id":"cTApgoHqxcIg"},"source":["collectionsを使うことで、各単語の出現回数をカウントすることができます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2GOwZvJixcIg"},"outputs":[],"source":["import collections\n","\n","t = Tokenizer()\n","\n","words = []\n","for sentence in wagahai_list:\n","    words += t.tokenize(sentence, wakati=True)# リストwordsに全ての単語を入れる\n","\n","c = collections.Counter(words)# 各単語の出現回数をカウント\n","print(c)"]},{"cell_type":"markdown","metadata":{"id":"Cj861mGUxcIg"},"source":["## 課題3:\n","課題2で前処理(ルビや不要な記号を除去)した.pickleを読み込んで、上記の方法で各単語数をカウントしてみましょう。  \n","「コーパスを分かち書き」で単語の分割を確認してから、「単語出現回数をカウント」すると結果がみやすくなるでしょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0EFc-ktLxcIg"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}