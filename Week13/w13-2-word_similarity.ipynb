{"cells":[{"cell_type":"markdown","metadata":{"id":"zd-TLsQYt0oa"},"source":["# 単語の類似度\n","word2vecによる分散表現を用いて、2つの単語の類似度を求めます。"]},{"cell_type":"markdown","metadata":{"id":"_bYj1ZJOt0ob"},"source":["## データの読み込み、及びword2vecによる学習\n","前回と同様に、データの読み込み及びword2vecによる学習を行います。<br>\n","wagahai_words.pickleを用いて分散表現（学習済みモデル）を生成します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"evByd_cLt0ob"},"outputs":[],"source":["import pickle\n","from gensim.models import word2vec\n","\n","with open('wagahai_words.pickle', mode='rb') as f:\n","    wagahai_words = pickle.load(f)\n","\n","print(wagahai_words)\n","\n","# size : 中間層のニューロン数\n","# min_count : この値以下の出現回数の単語を無視\n","# window : 対象単語を中心とした前後の単語数\n","# iter : epochs数\n","# sg : CBOWを使うかskip-gramを使うか 0:CBOW 1:skip-gram\n","model = word2vec.Word2Vec(wagahai_words,\n","                          size=100,\n","                          min_count=5,\n","                          window=5,\n","                          iter=20,\n","                          sg = 0)"]},{"cell_type":"markdown","metadata":{"id":"xFCUB-Pmt0ob"},"source":["## 類似度の高い単語\n","ある単語と類似度の高い単語を表示します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9OD0ZdYIt0oc"},"outputs":[],"source":["print(model.wv.most_similar(\"猫\"))  # 最も似ている単語"]},{"cell_type":"markdown","metadata":{"id":"rJ9TfxfSt0oc"},"source":["学習データが小さいため、今回はあまり興味深い結果にはなりません。  \n","興味のある方は、他の小説をなどをコーパスに加え、学習データを大きくしてみましょう。  \n","表示する個数のデフォルトは10です。表示個数を変更する場合は， `\"猫\", [], 個数`のように指定できます。\n","\n","単語の類似度は以下の式で表されるコサイン類似度で計算しています。  \n","ベクトル$\\vec{a}=(a_1,a_2,\\cdots, a_n)$、$\\vec{b}=(b_1,b_2,\\cdots, b_n)$として、\n","$$\\frac{a_1b_1+a_2b_2+\\cdots + a_nb_n}{\\sqrt{a_1^2+a_2^2+\\cdots+a_n^2}\\sqrt{b_1^2+b_2^2+\\cdots+b_n^2}}$$\n","\n","試しに、上式を用いたコサイン類似度を計算してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Vfoyosvt0oc"},"outputs":[],"source":["import numpy as np\n","\n","a = model.wv.__getitem__(\"猫\")\n","b = model.wv.__getitem__(\"人間\")\n","cos_sim = np.dot(a, b) / np.linalg.norm(a) / np.linalg.norm(b)  # linalg.normで二乗和の平方根（ノルム）を計算\n","print(cos_sim)"]},{"cell_type":"markdown","metadata":{"id":"rfO5Mh8at0oc"},"source":["猫と人間の類似度は、先ほどの結果と同じになっているでしょうか？"]},{"cell_type":"markdown","metadata":{"id":"lqb3c_Rvt0oc"},"source":["### 課題2:\n","1. 単語「名前」と類似度の高い単語を表示してみましょう。  \n","2. また、最も類似度が高い単語とのコサイン類似度を計算してみましょう。\n","\n","考察：納得いくの類似度でしたか？"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBE3aVX6t0oc"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}